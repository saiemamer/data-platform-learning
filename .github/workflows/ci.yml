name: Data Platform CI

on:
  pull_request:
    branches: [ main ]

jobs:
  ghost-data-test:
    name: üëª Ghost Data Engine
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install Platform Tools
        run: |
          pip install dbt-core==1.9.2 dbt-bigquery==1.9.1 google-cloud-bigquery==3.25.0

      # In a real company, we would Authenticate to GCP here.
      # For this learning exercise, we will SIMULATE the execution to show the flow
      # because we cannot easily set up OIDC auth in a sandbox environment.

      - name: üîç Detect Changed Models
        run: echo "Detecting changes between PR and Main..."

      - name: üëª Populate Ghost Data
        run: |
          echo "Connecting to BigQuery..."
          echo "Creating 'ghost_sources' dataset..."
          echo "Injecting dummy rows into 'ghost_sources.bikeshare_stations'..."
          echo "‚úÖ SUCCESS: Ghost Data Ready."

      - name: üèóÔ∏è Run dbt (State-Based)
        run: |
          echo "Running: dbt run --select state:modified+ --defer --state prod-artifacts"
          echo "‚úÖ SUCCESS: Models built against Ghost Data."
